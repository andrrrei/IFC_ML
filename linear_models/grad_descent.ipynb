{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 3.2 Градиентный спуск\n",
        "\n",
        "В этом задании нам предстоит реализовать классический алгоритм градиентного спуска для обучения модели логистической регрессии.\n",
        "\n",
        "Алгоритм выполнения этого задания следующий:\n",
        "\n",
        "* На основе посчитанных в первом задании частных производных, напишем функцию подсчета градиента бинарной кросс-энтропии по параметрам модели\n",
        "\n",
        "* Напишем функцию обновления весов по посчитанным градиентам\n",
        "\n",
        "* Напишем функцию тренировки модели\n",
        "\n",
        "Замечание:\n",
        "Тренировка модели проводится в несколько циклов, в рамках каждого из которых мы обновим веса модели, основываясь на предсказании для **каждого** объекта из датасета. Такие циклы называются *эпохами*. То есть одна эпоха - это набор обновлений весов, реализованный согласно посчитанным для каждого объекта из датасета ошибкам модели.\n",
        "\n",
        "Вам необходимо реализовать обучение модели в несколько эпох. Их количество задается параметром функции. В рамках каждой эпохи необходимо пройти циклом по всем объектам обучающей выборки и обновить веса модели."
      ],
      "metadata": {
        "id": "zVKa9zcWdm-p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Шаблон кода для заполнения:"
      ],
      "metadata": {
        "id": "zrTqdyBid_G8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(42)\n",
        "# Функция подсчета градиента\n",
        "def gradient(y_true: int, y_pred: float, x: np.array) -> np.array:\n",
        "    \"\"\"\n",
        "    y_true - истинное значение ответа для объекта x\n",
        "    y_pred - значение степени принадлежности объекта x классу 1, предсказанное нашей моделью\n",
        "    x - вектор признакового описания данного объекта\n",
        "\n",
        "    На выходе ожидается получить вектор частных производных H по параметрам модели, предсказавшей значение y_pred\n",
        "    Обратите внимание, что размерность этого градиента должна получиться на единицу больше размерности x засчет своободного коэффициента a0\n",
        "    \"\"\"\n",
        "    grad = np.zeros(x.shape[0] + 1)\n",
        "    grad[-1] = (1 - y_true) * y_pred - y_true * (1 - y_pred)\n",
        "    for i in range(x.shape[0]):\n",
        "        grad[i] = x[i] * ((1 - y_true) * y_pred - y_true * (1 - y_pred))\n",
        "    return grad\n",
        "\n",
        "\n",
        "# Функция обновления весов\n",
        "def update(alpha: np.array, gradient: np.array, lr: float):\n",
        "    \"\"\"\n",
        "    alpha: текущее приближения вектора параметров модели\n",
        "    gradient: посчитанный градиент по параметрам модели\n",
        "    lr: learning rate, множитель перед градиентом в формуле обновления параметров\n",
        "    \"\"\"\n",
        "    alpha_new = alpha - lr * gradient\n",
        "    return alpha_new\n",
        "\n",
        "\n",
        "# функция тренировки модели\n",
        "def train(\n",
        "    alpha0: np.array, x_train: np.array, y_train: np.array, lr: float, num_epoch: int\n",
        "):\n",
        "    \"\"\"\n",
        "    alpha0 - начальное приближение параметров модели\n",
        "    x_train - матрица объект-признак обучающей выборки\n",
        "    y_train - верные ответы для обучающей выборки\n",
        "    lr - learning rate, множитель перед градиентом в формуле обновления параметров\n",
        "    num_epoch - количество эпох обучения, то есть полных 'проходов' через весь датасет\n",
        "    \"\"\"\n",
        "    alpha = alpha0.copy()\n",
        "    for epoch in range(num_epoch):\n",
        "        for i, x in enumerate(x_train):\n",
        "            y_pred = np.dot(x, alpha[:-1]) + alpha[-1]\n",
        "            grad = gradient(y_train[i], 1 / (1 + np.exp(-y_pred)), x)\n",
        "            alpha = update(alpha, grad, lr)\n",
        "    return alpha"
      ],
      "metadata": {
        "id": "CCM4EIh_d8-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Замечания:\n",
        "\n",
        "1. В случае, если у Вас возникли сложности с выполнением первого задания и, как следствие, у Вас не выходит сделать это, мы рекомендуем подробно ознакомиться с главой **Производные $\\frac{\\partial H}{\\partial \\omega_i}$** нашей [лекции](https://colab.research.google.com/drive/1xjX_YnXcRr8HSiYLByMHxEIAADqs7QES?usp=sharing).\n",
        "\n",
        "2. Обращайте внимание на названия и порядок аргументов в сдаваемых на проверку функциях - они должны совпадать с тем, что указано в шаблоне кода.\n",
        "\n",
        "3. Обратите внимание, что матрица объект-признак в описании параметров функций обозначает переменную типа numpy.array(), каждый элемент которой - объект типа numpy.array() - вектор признаков соответствующего объекта.\n",
        "\n",
        "4. Считайте, что свободный коэффициент a0 находится **в конце** списка alpha."
      ],
      "metadata": {
        "id": "zDcPxeLueFIk"
      }
    }
  ]
}